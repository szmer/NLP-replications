{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plumbing\n",
    "1. Download the phrase similarity dataset from http://homepages.inf.ed.ac.uk/mlap/resources/index.html, save as `phrase_similarities.txt`\n",
    "2. Download the EasyCCG parser from http://homepages.inf.ed.ac.uk/s1049478/easyccg.html, unpack the package (you should get a catalog like `easyccg-0.2`). From the same page, download the regular pretrained model (`model.tar.gz`). Unpack the model to the parser's catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the British National Corpus & the word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BNCCorpusReader in '/home/szymon/lingwy/trening_głębi/repo/01-The Role of Syntax in Vector Space Models (Hermann & Blunsom 2013)/BNC/Texts'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.bnc import BNCCorpusReader\n",
    "bnc = BNCCorpusReader(root='BNC/Texts/', fileids=r'[A-K]/\\w*/\\w*\\.xml', lazy=False) # https://github.com/nltk/nltk/issues/781\n",
    "print(bnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['FACTSHEET', 'WHAT', 'IS', 'AIDS', '?'], ['AIDS', '(', 'Acquired', 'Immune', 'Deficiency', 'Syndrome', ')', 'is', 'a', 'condition', 'caused', 'by', 'a', 'virus', 'called', 'HIV', '(', 'Human', 'Immuno', 'Deficiency', 'Virus', ')', '.'], ['This', 'virus', 'affects', 'the', 'body', \"'s\", 'defence', 'system', 'so', 'that', 'it', 'can', 'not', 'fight', 'infection', '.'], ['How', 'is', 'infection', 'transmitted', '?'], ['through', 'unprotected', 'sexual', 'intercourse', 'with', 'an', 'infected', 'partner', '.'], ['through', 'infected', 'blood', 'or', 'blood', 'products', '.'], ['from', 'an', 'infected', 'mother', 'to', 'her', 'baby', '.'], ['It', 'is', 'not', 'transmitted', 'from', ':'], ['giving', 'blood/mosquito', 'bites/toilet', 'seats/kissing/from', 'normal', 'day-to-day', 'contact'], ['How', 'does', 'it', 'affect', 'you', '?']]\n"
     ]
    }
   ],
   "source": [
    "print(bnc.sents()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d5587171824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# A word->id mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0munique_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# A word->id mapping.\n",
    "unique_words = set(bnc.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'overplayful', 'garage-less', 'TRINZIC', 'fileserver', 'M6', 'ultra-refined', '341,000,000', 'welldisciplined', 'shitkickers']\n",
      "762481\n"
     ]
    }
   ],
   "source": [
    "unique_words = list(unique_words)\n",
    "print(unique_words[:10])\n",
    "unique_count = len(unique_words)\n",
    "print(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540129\n"
     ]
    }
   ],
   "source": [
    "# try stemming just for the embedding?\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in unique_words]\n",
    "stemmed_words = list(set(stemmed_words))\n",
    "print(len(stemmed_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting CCG parse trees for BNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ID=1\\n(<T S[dcl] 1 2> (<T NP[nb] 0 2> (<L NP[nb]/N POS POS The NP[nb]/N>) (<L N POS POS cat N>) ) (<T S[dcl]\\\\NP 0 2> (<L (S[dcl]\\\\NP)/NP POS POS chases (S[dcl]\\\\NP)/NP>) (<T NP[nb] 0 2> (<T NP[nb] 0 2> (<L NP[nb]/N POS POS a NP[nb]/N>) (<L N POS POS ball N>) ) (<T NP\\\\NP 0 2> (<L (NP\\\\NP)/NP POS POS of (NP\\\\NP)/NP>) (<T NP 0 1> (<L N POS POS yarn. N>) ) ) ) ) ) \\n' \n",
      " b'Loading model...\\nModel loaded, ready to parse.\\n'\n"
     ]
    }
   ],
   "source": [
    "# we will run the underlying parser as a subprocess, and intercept its outputs from within Python\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "p = Popen(['java', '-jar', 'easyccg-0.2/easyccg.jar', '--model', 'easyccg-0.2/model'], stdout=PIPE, stdin=PIPE, stderr=PIPE)\n",
    "# .encode() gives bytes instead of str, as .communicate() requires. We get a pair (stdout, stderr):\n",
    "(parse, err) = p.communicate(input='The cat chases a ball of yarn.\\n'.encode())\n",
    "print(parse, '\\n', err)\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how NLTK can handle parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<T\n",
      "  S[dcl]\n",
      "  1\n",
      "  2>\n",
      "  (<T\n",
      "    NP[nb]\n",
      "    0\n",
      "    2>\n",
      "    (<L NP[nb]/N POS POS The NP[nb]/N>)\n",
      "    (<L N POS POS cat N>))\n",
      "  (<T\n",
      "    S[dcl]\\\\NP\n",
      "    0\n",
      "    2>\n",
      "    (<L (S[dcl]\\\\NP ) /NP POS POS chases (S[dcl]\\\\NP ) /NP>)\n",
      "    (<T\n",
      "      NP[nb]\n",
      "      0\n",
      "      2>\n",
      "      (<T\n",
      "        NP[nb]\n",
      "        0\n",
      "        2>\n",
      "        (<L NP[nb]/N POS POS a NP[nb]/N>)\n",
      "        (<L N POS POS ball N>))\n",
      "      (<T\n",
      "        NP\\\\NP\n",
      "        0\n",
      "        2>\n",
      "        (<L (NP\\\\NP ) /NP POS POS of (NP\\\\NP ) /NP>)\n",
      "        (<T NP 0 1> (<L N POS POS yarn. N>))))))\n"
     ]
    }
   ],
   "source": [
    "# some string cleanup\n",
    "def clean_parse_output(parse_output):\n",
    "    # (remember we have to deal with the parse returned as bytes, not a Unicode string)\n",
    "    return str(parse_output).split('\\\\n')[1] # the second line contains the parse itself\n",
    "\n",
    "from nltk.tree import Tree\n",
    "tree = Tree.fromstring(clean_parse_output(parse))\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's not very pretty, because NLTK decides to print a newline instead of space inside the less/more than signs. In each (parenthesized expression), the first item (head) is the category of node, and two next items are its child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#p = Popen(['java', '-jar', 'easyccg-0.2/easyccg.jar', '--model', 'easyccg-0.2/model'], stdout=PIPE, stdin=PIPE, stderr=PIPE)\n",
    "\n",
    "trees = []#[ None ] * len(bnc.sents())\n",
    "for (sent_n, sent) in enumerate(bnc.sents()):\n",
    "    input_sent = (' '.join(sent)+'\\n').encode()\n",
    "    #parse_out = p.communicate(input=input_sent)\n",
    "    #trees[sent_n] = parse_str\n",
    "    trees.append(input_sent)\n",
    "    #if sent_n > 100:\n",
    "    #    break\n",
    "\n",
    "#p.terminate()\n",
    "print(trees[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
